# DrawGestures-NeutonAI

Whenever I get time, I hunt for ways to make myself super-productive either by reducing daily tasks like opening WhatsApp, checking emails and contacts. Long before we started swiping and tapping on touch screens, mouse gestures were touted as the humanist way of interacting with our computers. Simple patterns you traced on screen by holding a mouse button in order to perform a shortcut,  mostly because clicking a button or swiping on a trackpad is always going to be a quicker way to do something on a PC than memorizing and executing an obscure command glyph.
But while mouse gestures make little sense on the PC, it turns out they’re a natural fit on touch-screen devices. System shortcuts just by drawing a symbol on the screen. And I’ve got to admit, it’s such a natural way to interact with a touch screen and very fast indeed. Keyboards, although much improved over the years, require a lot of attention to hit the right buttons. :-()

# Introduction
In this project, we will learn how to make a Machine Learning model for an embedded device to recognize complex drawing gestures like digits, alphabets, and special symbols on TFT touch screen display units. I will also explain how this project might benefit from using such drawing gestures to add fun to our productivity.

Full project on hackster. https://hackster.io/vilaksh01
